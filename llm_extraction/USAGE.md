# Korean Document Metadata Extraction - Usage Guide

## ğŸš€ Quick Start

### 1. Setup
```bash
cd Project/llm_extraction
python setup.py
```

### 2. Test the System (First run will download models)
```bash
python extract_metadata.py --test
```

### 3. Process OCR Results
```bash
python extract_metadata.py --ocr-results-dir ../OCR/google_vision/ocr_results --output-dir metadata_results
```

## ğŸ—‚ï¸ Model Cache Management

### **First-Time Setup**
When you run the system for the first time, models will be automatically downloaded:
- **SOLAR-Ko-10.7B**: ~20GB download
- **Qwen2.5-7B**: ~15GB download  
- **SOLAR-Ko-1.7B**: ~3GB download

### **Cache Commands**
```bash
# List all cached models
python cleanup_cache.py --list

# Show cache statistics
python cleanup_cache.py --stats

# Clean up models unused for 30 days
python cleanup_cache.py --cleanup --days 30

# Remove all cached models (frees up ~38GB)
python cleanup_cache.py --cleanup-all --yes

# Verify model integrity
python cleanup_cache.py --verify primary
```

### **Cache Benefits**
- **âš¡ Faster Loading**: Subsequent runs load from local cache
- **ğŸŒ Offline Mode**: Works without internet after initial download
- **ğŸ’¾ Storage Control**: Models stored in `models/hf_models/`
- **ğŸ”„ Consistent Versions**: Same model version across runs

## ğŸ“‹ Available Models

### **SOLAR-Ko-10.7B** (Default - Recommended)
- **Best for**: Korean documents, legal contracts
- **Accuracy**: High
- **Speed**: Medium
- **Memory**: ~16GB RAM
```bash
python extract_metadata.py --model solar-ko --test
```

### **Qwen2.5-7B** (Alternative)
- **Best for**: Multilingual documents
- **Accuracy**: High
- **Speed**: Fast
- **Memory**: ~12GB RAM
```bash
python extract_metadata.py --model qwen --test
```

### **SOLAR-Ko-1.7B** (Lightweight)
- **Best for**: Resource-constrained environments
- **Accuracy**: Medium
- **Speed**: Very Fast
- **Memory**: ~6GB RAM
```bash
python extract_metadata.py --model lightweight --test
```

## ğŸ¯ Usage Examples

### Test with Sample Data
```bash
python extract_metadata.py --test --model solar-ko
```

### Process All OCR Results
```bash
python extract_metadata.py \
  --ocr-results-dir ../OCR/google_vision/ocr_results \
  --output-dir metadata_results \
  --model solar-ko
```

### Process Specific Provider Results
```bash
python extract_metadata.py \
  --ocr-results-dir ../OCR/google_vision/ocr_results/mistral_ocr \
  --output-dir mistral_metadata \
  --model qwen
```

## ğŸ“Š Output Structure

```
metadata_results/
â”œâ”€â”€ extraction_summary.json          # Overall statistics and results
â”œâ”€â”€ google_cloud_ocr_ê³„ì•½ì„œ_[doc]_metadata.json
â”œâ”€â”€ google_cloud_ocr_ë™ì˜ì„œ_[doc]_metadata.json
â”œâ”€â”€ mistral_ocr_ê³„ì•½ì„œ_[doc]_metadata.json
â””â”€â”€ mistral_ocr_ë™ì˜ì„œ_[doc]_metadata.json
```

## ğŸ—ï¸ System Architecture

The system follows a modular architecture:

```
ğŸ“ llm_extraction/
â”œâ”€â”€ ğŸ“„ extract_metadata.py          # Main CLI interface
â”œâ”€â”€ ğŸ“„ setup.py                     # Automated setup
â”œâ”€â”€ ğŸ“ models/
â”‚   â””â”€â”€ ğŸ“„ base_extractor.py        # LLM model implementations
â”œâ”€â”€ ğŸ“ extractors/
â”‚   â””â”€â”€ ğŸ“„ document_extractors.py   # Document-specific logic
â”œâ”€â”€ ğŸ“ schemas/
â”‚   â””â”€â”€ ğŸ“„ document_schemas.py      # JSON schema definitions
â””â”€â”€ ğŸ“ config/
    â””â”€â”€ ğŸ“„ model_config.yaml        # Model configurations
```

### **Processing Flow:**
1. **Input**: OCR text files from `../OCR/google_vision/ocr_results/`
2. **Schema Selection**: Choose appropriate JSON schema based on document type
3. **LLM Processing**: SOLAR-Ko/Qwen/Qwen2.5-72B/Qwen3-4B/Llama/Gemma3/Mixtral extracts structured metadata
4. **Post-processing**: Clean and validate extracted data
5. **Output**: Save structured JSON metadata files

## âœ… Implementation Status

**Fully Implemented Components:**
- âœ… **Core LLM Extractors**: SOLAR-Ko, Qwen, Qwen2.5-72B, Qwen3-4B, Llama, Gemma 3, Mixtral, and lightweight models
- âœ… **JSON Schema System**: Contract and consent form schemas
- âœ… **Document Extractors**: Specialized processing for different document types
- âœ… **Batch Processing**: Automated processing of OCR results
- âœ… **CLI Interface**: Command-line interface with multiple options
- âœ… **Error Handling**: Comprehensive error handling and retry mechanisms
- âœ… **Logging**: Detailed logging for debugging and monitoring
- âœ… **Setup Script**: Automated dependency installation and setup

**Ready for Production Use!** ğŸš€

## ğŸ” Extracted Metadata Fields

### **Contracts (ê³„ì•½ì„œ)**
- `contract_type`: ê³„ì•½ì„œ ìœ í˜•
- `rights_holder`: ê¶Œë¦¬ì
- `user`: ì´ìš©ì
- `work_title`: ì €ì‘ë¬¼ ì œëª©
- `work_category`: ì €ì‘ë¬¼ ì¢…ë³„
- `granted_rights`: í—ˆë½ëœ ê¶Œë¦¬
- `contract_purpose`: ê³„ì•½ì˜ ëª©ì 
- `payment_amount`: ì§€ê¸‰ ê¸ˆì•¡
- `signature_date`: ê³„ì•½ ì²´ê²°ì¼
- `special_terms`: íŠ¹ë³„ ì•½ì • ì‚¬í•­

### **Consent Forms (ë™ì˜ì„œ)**
- `consent_type`: ë™ì˜ì„œ ìœ í˜•
- `data_controller`: ê°œì¸ì •ë³´ ì²˜ë¦¬ì
- `data_subject`: ì •ë³´ì£¼ì²´
- `collection_purpose`: ìˆ˜ì§‘ ëª©ì 
- `collected_data_types`: ìˆ˜ì§‘ í•­ëª©
- `retention_period`: ë³´ìœ  ê¸°ê°„
- `consent_status`: ë™ì˜ ì—¬ë¶€
- `consent_date`: ë™ì˜ì¼
- `contact_info`: ì—°ë½ì²˜ ì •ë³´

## âš™ï¸ Configuration

### Model Configuration (`config/model_config.yaml`)
```yaml
models:
  primary:
    name: "SOLAR-Ko-10.7B"
    model_id: "upstage/SOLAR-10.7B-Instruct-v1.0"
    max_length: 4096
    temperature: 0.1
    top_p: 0.9
```

### Custom Schema
You can modify schemas in `schemas/document_schemas.py` to add new fields or change extraction logic.

## ğŸ› ï¸ Troubleshooting

### **Out of Memory Error**
- Use `--model lightweight` for smaller model
- Reduce `max_length` in config
- Close other applications

### **Slow Processing**
- Use GPU if available
- Try `--model qwen` for faster processing
- Process smaller batches

### **Poor Extraction Quality**
- Use `--model solar-ko` for better Korean understanding
- Check OCR text quality
- Adjust `temperature` in config (lower = more focused)

## ğŸ“ˆ Performance Tips

1. **GPU Usage**: Ensure CUDA is available for faster processing
2. **Batch Processing**: Process multiple documents together
3. **Model Selection**: Choose appropriate model for your needs
4. **Text Preprocessing**: Clean OCR text before extraction

## ğŸ”§ Advanced Usage

### Custom Extraction
```python
from models.base_extractor import create_extractor
from extractors.document_extractors import DocumentMetadataExtractor

# Create extractor
extractor = create_extractor("solar-ko")
doc_extractor = DocumentMetadataExtractor(extractor)

# Extract metadata
result = doc_extractor.extract_metadata(text, "ê³„ì•½ì„œ", "document_name")
print(result.metadata)
```

### Batch Processing with Custom Logic
```python
# Process specific document types only
results = []
for doc_type in ["ê³„ì•½ì„œ"]:  # Only contracts
    result = doc_extractor.extract_metadata(text, doc_type, doc_name)
    results.append(result)
```

## ğŸ“ Support

For issues or questions:
1. Check logs in `logs/` directory
2. Run with `--test` to verify setup
3. Check GPU availability with `python -c "import torch; print(torch.cuda.is_available())"`
