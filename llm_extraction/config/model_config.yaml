# Model Configuration for Korean Metadata Extraction

# Cache Configuration
cache:
  enabled: true
  local_dir: "../hf_models"
  force_download: false
  cleanup_unused: true

models:
  primary:
    name: "SOLAR-Ko-10.7B"
    model_id: "upstage/SOLAR-10.7B-Instruct-v1.0"
    local_path: "../hf_models/SOLAR-10.7B-Instruct-v1.0"
    max_length: 4096
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  secondary:
    name: "Qwen2.5-7B"
    model_id: "Qwen/Qwen2.5-7B-Instruct"
    local_path: "../hf_models/Qwen2.5-7B-Instruct"
    max_length: 4096
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  lightweight:
    name: "SOLAR-Ko-1.7B"
    model_id: "upstage/SOLAR-1.7B-Instruct-v1.0"
    local_path: "../hf_models/SOLAR-1.7B-Instruct-v1.0"
    max_length: 2048
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  llama:
    name: "Llama-3.1-70B"
    model_id: "meta-llama/Llama-3.1-70B-Instruct"
    local_path: "../hf_models/Llama-3.1-70B-Instruct"
    max_length: 8192
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  qwen72b:
    name: "Qwen2.5-72B"
    model_id: "Qwen/Qwen2.5-72B-Instruct"
    local_path: "../hf_models/Qwen2.5-72B-Instruct"
    max_length: 8192
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  qwenvl:
    name: "Qwen2.5-VL-72B"
    model_id: "Qwen/Qwen2.5-VL-72B-Instruct"
    local_path: "../hf_models/Qwen2.5-VL-72B-Instruct"
    max_length: 8192
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  qwen3:
    name: "Qwen3-4B"
    model_id: "Qwen/Qwen3-4B-Instruct-2507"
    local_path: "../hf_models/Qwen3-4B-Instruct-2507"
    max_length: 4096
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  gemma3_12b:
    name: "Gemma3-12B"
    model_id: "google/gemma-3-12b-it"
    local_path: "../hf_models/gemma-3-12b-it"
    max_length: 131072
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  mixtral_8x7b:
    name: "Mixtral-8x7B"
    model_id: "mistralai/Mixtral-8x7B-Instruct-v0.1"
    local_path: "../hf_models/Mixtral-8x7B-Instruct-v0.1"
    max_length: 32768
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  qwen3_next_80b:
    name: "Qwen3-Next-80B"
    model_id: "Qwen/Qwen3-Next-80B-A3B-Instruct"
    local_path: "../hf_models/Qwen3-Next-80B-A3B-Instruct"
    max_length: 256000
    temperature: 0.1 # or 0.7
    top_p: 0.9 # or 0.8
    # top_k: 20
    # MinP:0
    device: "auto"
    
  qwen3_30b:
    name: "Qwen3-30B"
    model_id: "Qwen/Qwen3-30B-A3B-Instruct-2507"
    local_path: "../hf_models/Qwen3-30B-A3B-Instruct-2507"
    max_length: 128000
    temperature: 0.1
    top_p: 0.9
    device: "auto"
    
  qwen3_235b:
    name: "Qwen3-235B"
    model_id: "Qwen/Qwen3-235B-A22B-Instruct-2507"
    local_path: "../hf_models/Qwen3-235B-A22B-Instruct-2507"
    max_length: 128000
    temperature: 0.1
    top_p: 0.9
    device: "auto"

extraction:
  batch_size: 1
  max_retries: 3
  timeout: 300
  
output:
  format: "json"
  include_confidence: true
  include_raw_response: false
