"""
Cloud-based Model Extractors for LLM Metadata Extraction

This module provides alternatives to local model storage by using cloud APIs
and inference services for metadata extraction.
"""

import os
import json
import logging
import requests
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class CloudExtractor(ABC):
    """Abstract base class for cloud-based extractors."""
    
    def __init__(self, api_key: str, model_id: str):
        self.api_key = api_key
        self.model_id = model_id
    
    @abstractmethod
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using cloud API."""
        pass


class HuggingFaceInferenceExtractor(CloudExtractor):
    """Hugging Face Inference API extractor."""
    
    def __init__(self, api_key: str, model_id: str):
        super().__init__(api_key, model_id)
        self.base_url = "https://api-inference.huggingface.co/models"
        self.headers = {"Authorization": f"Bearer {api_key}"}
    
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using Hugging Face Inference API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 2048,
                "temperature": 0.1,
                "top_p": 0.8,
                "return_full_text": False
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/{self.model_id}",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result[0]["generated_text"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "huggingface_inference",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"Hugging Face API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""ÎãπÏã†ÏùÄ ÌïúÍµ≠Ïñ¥ Î¨∏ÏÑú(Í≥ÑÏïΩÏÑú, ÎèôÏùòÏÑú, Í∏∞ÌÉÄ)ÏóêÏÑú Ï†ïÎ≥¥Î•º Ï∂îÏ∂úÌïòÎäî ÎèÑÏö∞ÎØ∏ÏûÖÎãàÎã§.
Î∞òÎìúÏãú Ïú†Ìö®Ìïú JSONÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî. ÏÑ§Î™Ö¬∑Ï£ºÏÑù¬∑ÎßàÌÅ¨Îã§Ïö¥¬∑ÏΩîÎìúÎ∏îÎ°ù Í∏àÏßÄ.

Îã§ÏùåÏùÄ {document_type} Î¨∏ÏÑúÏùò OCR ÌÖçÏä§Ìä∏ÏûÖÎãàÎã§. Ï£ºÏñ¥ÏßÑ JSON Ïä§ÌÇ§ÎßàÏóê Îî∞Îùº Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî.

Î¨∏ÏÑú ÌÖçÏä§Ìä∏:
{text}

Ï∂îÏ∂úÌï† Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ïä§ÌÇ§Îßà:
{schema_str}

ÏßÄÏãúÏÇ¨Ìï≠:
1. ÌÖçÏä§Ìä∏ÏóêÏÑú Í∞Å ÌïÑÎìúÏóê Ìï¥ÎãπÌïòÎäî Ï†ïÎ≥¥Î•º Ï†ïÌôïÌûà Ï∞æÏïÑ Ï∂îÏ∂úÌïòÏÑ∏Ïöî
2. Ï†ïÎ≥¥Í∞Ä Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï°¥Ïû¨ÌïòÏßÄ ÏïäÍ±∞ÎÇò Î∂àÎ∂ÑÎ™ÖÌïú Í≤ΩÏö∞ Î∞òÎìúÏãú nullÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî (Ï∂îÏ∏° Í∏àÏßÄ)
3. ÎÇ†ÏßúÎäî YYYY-MM-DD ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌïòÏÑ∏Ïöî
4. Í∏àÏï°ÏùÄ Ïà´ÏûêÎßå Ï∂îÏ∂úÌïòÏÑ∏Ïöî (Îã®ÏúÑ Ï†úÏô∏)
5. Ï†ÑÌôîÎ≤àÌò∏Îäî Ïà´ÏûêÏôÄ ÌïòÏù¥Ìîà(-)Îßå Ìè¨Ìï®ÌïòÏÑ∏Ïöî
6. Ï£ºÏÜåÎäî Ï†ÑÏ≤¥ Ï£ºÏÜåÎ•º Ï†ïÌôïÌûà Ï∂îÏ∂úÌïòÏÑ∏Ïöî
7. ÏÇ¨ÏóÖÏûêÎì±Î°ùÎ≤àÌò∏Îäî Ïà´ÏûêÏôÄ ÌïòÏù¥Ìîà(-)Îßå Ìè¨Ìï®ÌïòÏÑ∏Ïöî
8. Ï≤¥ÌÅ¨Î∞ïÏä§ Ï†ïÎ≥¥ Ï≤òÎ¶¨:
   - Ï≤¥ÌÅ¨Î∞ïÏä§Í∞Ä Ï≤¥ÌÅ¨Îêú ÏÉÅÌÉú(üìß, ‚òë, ‚úì, ‚ñ†, ‚óè, ‚óº, ‚óâ)Ïù∏ Í≤ΩÏö∞ trueÎ°ú ÏÑ§Ï†ï
   - Ï≤¥ÌÅ¨Î∞ïÏä§Í∞Ä Ï≤¥ÌÅ¨ÎêòÏßÄ ÏïäÏùÄ ÏÉÅÌÉú(‚òê, ‚ñ°, ‚óã, ‚óØ, ‚óª, ‚ó¶)Ïù∏ Í≤ΩÏö∞ falseÎ°ú ÏÑ§Ï†ï
   - Ï≤¥ÌÅ¨Î∞ïÏä§ Ìå®ÌÑ¥ÏùÑ ÏûêÎèôÏúºÎ°ú Í∞êÏßÄÌïòÏó¨ ÏùºÍ¥ÄÏÑ± ÏûàÍ≤å Ï≤òÎ¶¨
   - OCR Ïò§Î•ò Í≥†Î†§: "Î™©Ï†úÍ∂å"ÏùÄ "Î≥µÏ†úÍ∂å"ÏúºÎ°ú Ìï¥ÏÑù
9. Î∞òÎìúÏãú Ïú†Ìö®Ìïú JSON ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌïòÏÑ∏Ïöî
10. Ï∂îÍ∞Ä Ï†ïÎ≥¥ÎÇò ÏÑ§Î™ÖÏùÄ Ìè¨Ìï®ÌïòÏßÄ ÎßàÏÑ∏Ïöî
11. ```jsonÏù¥ÎÇò ``` Í∞ôÏùÄ ÎßàÌÅ¨Îã§Ïö¥ Î¨∏Î≤ï ÏÇ¨Ïö© Í∏àÏßÄ

ÏùëÎãµ (JSONÎßå):"""


class OpenAIExtractor(CloudExtractor):
    """OpenAI API extractor."""
    
    def __init__(self, api_key: str, model_id: str = "gpt-4o-mini"):
        super().__init__(api_key, model_id)
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def extract_metadata(self, text: str, schema: Dict[str,Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using OpenAI API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": "You are a Korean document metadata extraction assistant."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "top_p": 0.8,
            "max_tokens": 2048
        }
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "openai",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"OpenAI API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""Extract metadata from this Korean {document_type} document text according to the provided JSON schema.

Document text:
{text}

Schema:
{schema_str}

Instructions:
1. Extract information for each field in the schema
2. Use null for missing or unclear information
3. Convert dates to YYYY-MM-DD format
4. Extract only numbers for amounts
5. Handle checkbox states (‚òë/‚òê, ‚úì/‚óã, ‚ñ†/‚ñ°, etc.)
6. Return only valid JSON without markdown formatting

Response (JSON only):"""


class TogetherAIExtractor(CloudExtractor):
    """Together AI API extractor."""
    
    def __init__(self, api_key: str, model_id: str):
        super().__init__(api_key, model_id)
        self.base_url = "https://api.together.xyz/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using Together AI API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": "You are a Korean document metadata extraction assistant."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "top_p": 0.8,
            "max_tokens": 2048
        }
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "together_ai",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"Together AI API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""Extract metadata from this Korean {document_type} document text according to the provided JSON schema.

Document text:
{text}

Schema:
{schema_str}

Instructions:
1. Extract information for each field in the schema
2. Use null for missing or unclear information
3. Convert dates to YYYY-MM-DD format
4. Extract only numbers for amounts
5. Handle checkbox states (‚òë/‚òê, ‚úì/‚óã, ‚ñ†/‚ñ°, etc.)
6. Return only valid JSON without markdown formatting

Response (JSON only):"""


def create_cloud_extractor(provider: str, api_key: str, model_id: str) -> CloudExtractor:
    """Factory function to create cloud extractors."""
    if provider.lower() == "huggingface":
        return HuggingFaceInferenceExtractor(api_key, model_id)
    elif provider.lower() == "openai":
        return OpenAIExtractor(api_key, model_id)
    elif provider.lower() == "together":
        return TogetherAIExtractor(api_key, model_id)
    else:
        raise ValueError(f"Unsupported cloud provider: {provider}")


# Example usage and configuration
if __name__ == "__main__":
    # Example configuration for cloud extractors
    cloud_config = {
        "huggingface": {
            "api_key": os.getenv("HUGGINGFACE_API_KEY"),
            "model_id": "upstage/SOLAR-10.7B-Instruct-v1.0"
        },
        "openai": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model_id": "gpt-4o-mini"
        },
        "together": {
            "api_key": os.getenv("TOGETHER_API_KEY"),
            "model_id": "meta-llama/Llama-2-7b-chat-hf"
        }
    }
    
    # Test cloud extractor
    provider = "huggingface"
    if cloud_config[provider]["api_key"]:
        extractor = create_cloud_extractor(
            provider,
            cloud_config[provider]["api_key"],
            cloud_config[provider]["model_id"]
        )
        
        # Test extraction
        test_text = "Í≥ÑÏïΩÏÑú ÎÇ¥Ïö©..."
        test_schema = {"title": "string", "date": "string"}
        
        result = extractor.extract_metadata(test_text, test_schema, "Í≥ÑÏïΩÏÑú")
        print(f"Cloud extraction result: {result}")
    else:
        print(f"No API key found for {provider}")
