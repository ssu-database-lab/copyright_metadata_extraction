"""
Cloud-based Model Extractors for LLM Metadata Extraction

This module provides alternatives to local model storage by using cloud APIs
and inference services for metadata extraction.
"""

import os
import json
import logging
import requests
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class CloudExtractor(ABC):
    """Abstract base class for cloud-based extractors."""
    
    def __init__(self, api_key: str, model_id: str):
        self.api_key = api_key
        self.model_id = model_id
    
    @abstractmethod
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using cloud API."""
        pass


class HuggingFaceInferenceExtractor(CloudExtractor):
    """Hugging Face Inference API extractor."""
    
    def __init__(self, api_key: str, model_id: str):
        super().__init__(api_key, model_id)
        self.base_url = "https://api-inference.huggingface.co/models"
        self.headers = {"Authorization": f"Bearer {api_key}"}
    
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using Hugging Face Inference API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 2048,
                "temperature": 0.1,
                "top_p": 0.8,
                "return_full_text": False
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/{self.model_id}",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result[0]["generated_text"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "huggingface_inference",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"Hugging Face API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ(ê³„ì•½ì„œ, ë™ì˜ì„œ, ê¸°íƒ€)ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ìž…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…Â·ì£¼ì„Â·ë§ˆí¬ë‹¤ìš´Â·ì½”ë“œë¸”ë¡ ê¸ˆì§€.

ë‹¤ìŒì€ {document_type} ë¬¸ì„œì˜ OCR í…ìŠ¤íŠ¸ìž…ë‹ˆë‹¤. ì£¼ì–´ì§„ JSON ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë¬¸ì„œ í…ìŠ¤íŠ¸:
{text}

ì¶”ì¶œí•  ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ:
{schema_str}

ì§€ì‹œì‚¬í•­:
1. í…ìŠ¤íŠ¸ì—ì„œ ê° í•„ë“œì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì •í™•ížˆ ì°¾ì•„ ì¶”ì¶œí•˜ì„¸ìš”
2. ì •ë³´ê°€ ëª…ì‹œì ìœ¼ë¡œ ì¡´ìž¬í•˜ì§€ ì•Šê±°ë‚˜ ë¶ˆë¶„ëª…í•œ ê²½ìš° ë°˜ë“œì‹œ nullì„ ì‚¬ìš©í•˜ì„¸ìš” (ì¶”ì¸¡ ê¸ˆì§€)
3. ë‚ ì§œëŠ” YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”
4. ê¸ˆì•¡ì€ ìˆ«ìžë§Œ ì¶”ì¶œí•˜ì„¸ìš” (ë‹¨ìœ„ ì œì™¸)
5. ì „í™”ë²ˆí˜¸ëŠ” ìˆ«ìžì™€ í•˜ì´í”ˆ(-)ë§Œ í¬í•¨í•˜ì„¸ìš”
6. ì£¼ì†ŒëŠ” ì „ì²´ ì£¼ì†Œë¥¼ ì •í™•ížˆ ì¶”ì¶œí•˜ì„¸ìš”
7. ì‚¬ì—…ìžë“±ë¡ë²ˆí˜¸ëŠ” ìˆ«ìžì™€ í•˜ì´í”ˆ(-)ë§Œ í¬í•¨í•˜ì„¸ìš”
8. ì²´í¬ë°•ìŠ¤ ì •ë³´ ì²˜ë¦¬:
   - ì²´í¬ë°•ìŠ¤ê°€ ì²´í¬ëœ ìƒíƒœ(ðŸ“§, â˜‘, âœ“, â– , â—, â—¼, â—‰)ì¸ ê²½ìš° trueë¡œ ì„¤ì •
   - ì²´í¬ë°•ìŠ¤ê°€ ì²´í¬ë˜ì§€ ì•Šì€ ìƒíƒœ(â˜, â–¡, â—‹, â—¯, â—», â—¦)ì¸ ê²½ìš° falseë¡œ ì„¤ì •
   - ì²´í¬ë°•ìŠ¤ íŒ¨í„´ì„ ìžë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì¼ê´€ì„± ìžˆê²Œ ì²˜ë¦¬
   - OCR ì˜¤ë¥˜ ê³ ë ¤: "ëª©ì œê¶Œ"ì€ "ë³µì œê¶Œ"ìœ¼ë¡œ í•´ì„
9. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”
10. ì¶”ê°€ ì •ë³´ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
11. ```jsonì´ë‚˜ ``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì‚¬ìš© ê¸ˆì§€

ì‘ë‹µ (JSONë§Œ):"""


class OpenAIExtractor(CloudExtractor):
    """OpenAI API extractor."""
    
    def __init__(self, api_key: str, model_id: str = "gpt-4o-mini"):
        super().__init__(api_key, model_id)
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def extract_metadata(self, text: str, schema: Dict[str,Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using OpenAI API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": "You are a Korean document metadata extraction assistant."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "top_p": 0.8,
            "max_tokens": 2048
        }
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "openai",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"OpenAI API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""Extract metadata from this Korean {document_type} document text according to the provided JSON schema.

Document text:
{text}

Schema:
{schema_str}

Instructions:
1. Extract information for each field in the schema
2. Use null for missing or unclear information
3. Convert dates to YYYY-MM-DD format
4. Extract only numbers for amounts
5. Handle checkbox states (â˜‘/â˜, âœ“/â—‹, â– /â–¡, etc.)
6. Return only valid JSON without markdown formatting

Response (JSON only):"""


class TogetherAIExtractor(CloudExtractor):
    """Together AI API extractor."""
    
    def __init__(self, api_key: str, model_id: str):
        super().__init__(api_key, model_id)
        self.base_url = "https://api.together.xyz/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def extract_metadata(self, text: str, schema: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """Extract metadata using Together AI API."""
        prompt = self._create_prompt(text, schema, document_type)
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": "You are a Korean document metadata extraction assistant."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "top_p": 0.8,
            "max_tokens": 2048
        }
        
        try:
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"]
            
            # Parse JSON response
            try:
                metadata = json.loads(extracted_text)
                return {
                    "metadata": metadata,
                    "model": self.model_id,
                    "provider": "together_ai",
                    "processing_time": None,
                    "confidence": None
                }
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON response: {extracted_text}")
                return {"error": "Invalid JSON response"}
                
        except requests.RequestException as e:
            logger.error(f"Together AI API error: {e}")
            return {"error": str(e)}
    
    def _create_prompt(self, text: str, schema: Dict[str, Any], document_type: str) -> str:
        """Create a structured prompt for metadata extraction."""
        schema_str = json.dumps(schema, ensure_ascii=False, indent=2)
        
        return f"""Extract metadata from this Korean {document_type} document text according to the provided JSON schema.

Document text:
{text}

Schema:
{schema_str}

Instructions:
1. Extract information for each field in the schema
2. Use null for missing or unclear information
3. Convert dates to YYYY-MM-DD format
4. Extract only numbers for amounts
5. Handle checkbox states (â˜‘/â˜, âœ“/â—‹, â– /â–¡, etc.)
6. Return only valid JSON without markdown formatting

Response (JSON only):"""


def create_cloud_extractor(provider: str, api_key: str, model_id: str) -> CloudExtractor:
    """Factory function to create cloud extractors."""
    if provider.lower() == "huggingface":
        return HuggingFaceInferenceExtractor(api_key, model_id)
    elif provider.lower() == "openai":
        return OpenAIExtractor(api_key, model_id)
    elif provider.lower() == "together":
        return TogetherAIExtractor(api_key, model_id)
    else:
        raise ValueError(f"Unsupported cloud provider: {provider}")


# Example usage and configuration
if __name__ == "__main__":
    # Example configuration for cloud extractors
    cloud_config = {
        "huggingface": {
            "api_key": os.getenv("HUGGINGFACE_API_KEY"),
            "model_id": "upstage/SOLAR-10.7B-Instruct-v1.0"
        },
        "openai": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model_id": "gpt-4o-mini"
        },
        "together": {
            "api_key": os.getenv("TOGETHER_API_KEY"),
            "model_id": "meta-llama/Llama-2-7b-chat-hf"
        }
    }
    
    # Test cloud extractor
    provider = "huggingface"
    if cloud_config[provider]["api_key"]:
        extractor = create_cloud_extractor(
            provider,
            cloud_config[provider]["api_key"],
            cloud_config[provider]["model_id"]
        )
        
        # Test extraction
        test_text = "ê³„ì•½ì„œ ë‚´ìš©..."
        test_schema = {"title": "string", "date": "string"}
        
        result = extractor.extract_metadata(test_text, test_schema, "ê³„ì•½ì„œ")
        print(f"Cloud extraction result: {result}")
    else:
        print(f"No API key found for {provider}")
